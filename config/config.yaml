# Base configuration for HPO (Lab 3)
# hydra.run.dir: . keeps cwd at project root for data paths
# Override via CLI: python src/optimize.py model=logistic_regression hpo.sampler=random

defaults:
  - model: random_forest
  - hpo: optuna

seed: 42

mlflow:
  tracking_uri: "file:./mlruns"
  experiment_name: "HPO_Lab3"
  log_model: true
  register_model: false  # true when MLflow tracking server + backend store available
  model_name: "BestOptimizedModel"
  stage: "Staging"

data:
  prepared_dir: "data/prepared"  # directory with train.csv, test.csv
  # target_type: "quartiles" (4 classes by popularity Q1â€“Q4) | "binary" (popularity >= threshold)
  target_type: "quartiles"
  popularity_threshold: 50  # used only when target_type: binary

model:
  type: "random_forest"  # overridden by config group (model/random_forest or model/logistic_regression)

hpo:
  n_trials: 20
  sampler: "tpe"  # overridden by group: hpo=optuna (tpe), hpo=random (random), hpo=grid (grid)
  metric: "f1"  # f1 | roc_auc (roc_auc often more stable for imbalanced data)
  direction: "maximize"
  use_cv: true   # 5-fold CV for more stable HPO (fewer F1=0 trials)
  cv_folds: 5
  # Search space for Random Forest
  random_forest:
    n_estimators: { low: 50, high: 300 }
    max_depth: { low: 3, high: 15 }
    min_samples_split: { low: 2, high: 10 }
    min_samples_leaf: { low: 1, high: 5 }
  # Search space for Logistic Regression
  logistic_regression:
    C: { low: 1.0e-3, high: 1.0e2 }
    solver: ["liblinear", "lbfgs"]
    penalty: ["l2"]
  # GridSampler search space (when sampler=grid)
  grid:
    random_forest:
      n_estimators: [50, 100, 200]
      max_depth: [5, 10, 15]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
    logistic_regression:
      C: [0.01, 0.1, 1.0, 10.0]
      solver: ["liblinear"]
      penalty: ["l2"]

hydra:
  run:
    dir: .
  output_subdir: null
