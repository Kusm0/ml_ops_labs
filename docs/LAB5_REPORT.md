# Звіт з Лабораторної роботи 5. Оркестрація ML-пайплайнів

## Відтворюваність

- **Seed:** у `scripts/train_ci.py` використовується `--random-state 42` (за замовчуванням).
- **Версія даних:** DVC — хеш у `dvc.lock` для стадій prepare/train; при потребі `dvc status` або `git show dvc.lock`.
- **Версія коду:** git commit hash при звіті — `git rev-parse HEAD`.
- **Конфігурація:** поріг accuracy для гілки DAG — `ML_ACCURACY_THRESHOLD` (за замовчуванням 0.85); корінь проєкту в Airflow — `ML_PROJECT_ROOT` (за замовчуванням `/opt/airflow/ml_project`).

---

## Архітектурні рішення

### Вибір операторів Airflow

- **FileSensor** — перевірка наявності сирих даних (`data/raw/dataset.csv`) перед запуском пайплайну; уникнення помилок через відсутній файл і можливість чекати появу файлу (poke).
- **BashOperator** — для кроків prepare і train: виконання `dvc repro prepare` та `python scripts/train_ci.py` у тому ж середовищі, де встановлені DVC та ML-бібліотеки (образ Airflow з `requirements.txt`), без додаткової абстракції DockerOperator.
- **PythonOperator** — evaluate (читання `metrics.json` і повернення словника в XCom) та register_model (завантаження `model.pkl`, MLflow Client API): логіка на Python, зручно для роботи з файлами та MLflow.
- **BranchPythonOperator** — умовне розгалуження за метрикою accuracy (поріг 0.85): реєстрація в MLflow або завершення пайплайну без реєстрації.
- **EmptyOperator** — гілка «stop_pipeline»: явне завершення без додаткової роботи (замість DummyOperator у Airflow 2.x).

### Стратегія тестування DAG

- У CI (GitHub Actions) після встановлення `apache-airflow` виконується тест `tests/test_dag_integrity.py`.
- Тест створює `DagBag(dag_folder='dags/', include_examples=False)` і перевіряє: `len(dag_bag.import_errors) == 0` та наявність DAG `ml_training_pipeline`.
- Це виявляє синтаксичні помилки, помилки імпорту (відсутні модулі/оператори), некоректні посилання в DAG до того, як зміни потраплять у виконання в Airflow.

---

## Відповіді на контрольні запитання

**1. Як взаємодіють компоненти CI/CD (GitHub Actions) та Оркестратор (Airflow)? Що запускає що?**

CI/CD і Airflow працюють паралельно і доповнюють один одного. GitHub Actions запускається при push/PR: перевіряє якість коду (lint), коректність DAG (DagBag), збірку Docker-образу, підготовку даних, тренування (train_ci), тести та Quality Gate. Він не запускає Airflow. Airflow працює окремо (локально або на сервері): за розкладом або вручну (Trigger DAG) виконує DAG ml_training_pipeline (перевірка даних → prepare → train → evaluate → branch → register/stop). Тобто CI/CD перевіряє і доставляє *код і конфігурацію*; оркестратор виконує *пайплайн даних і моделей* (Continuous Training).

**2. Які переваги дає використання DAG порівняно з лінійним скриптом (run_all.sh)?**

DAG дає явні залежності між задачами, паралелізацію де можливо, повторні запуски (retries) при збоях, централізовані логи та моніторинг у UI, розгалуження за умовами (наприклад, реєструвати модель лише при досягненні порогу). Лінійний скрипт виконує кроки по черзі без видимості графа, без вбудованих retry та гнучкого розгалуження.

**3. Навіщо потрібен BranchPythonOperator і в яких сценаріях MLOps він використовується?**

Він потрібен для умовного вибору наступної задачі на основі результатів попередніх (наприклад, метрик з XCom). У MLOps: реєструвати модель тільки якщо метрика перевищує поріг; відправляти на перетренування або сповіщення при деградації; вибирати різні шляхи валідації (A/B, канари) залежно від результату оцінки.

**4. Як Multi-stage build впливає на безпеку та швидкість розгортання контейнерів?**

У фінальний образ не потрапляють інструменти збірки та зайві залежності — зменшується поверхня атаки. Образ легший і швидше завантажується при pull/run, що прискорює CI/CD та розгортання. Менший розмір також зменшує ризик вразливостей з непотрібних пакетів.

**5. Чому важливо тестувати DAG-файли на етапі CI/CD? Які типи помилок це дозволяє виявити?**

Щоб зламаний або некоректний DAG не потрапляв у Airflow і не блокував пайплайни. Тест через DagBag виявляє: синтаксичні помилки в Python, помилки імпорту (відсутні оператори/модулі), помилки при парсингу DAG (невалідні task_id, циклічні залежності тощо), тобто перевірку проходить лише коректний код DAG.

**6. Архітектура Apache Airflow: за що відповідають Scheduler, Webserver та Executor?**

- **Scheduler** — читає DAG-и, визначає, які задачі готові до виконання (залежності виконані, розклад/тригер), і ставить їх у чергу на виконання.
- **Webserver** — веб-інтерфейс для перегляду DAG-ів, логів, статусів задач, ручного запуску (Trigger) та налаштувань.
- **Executor** — визначає, *де* виконувати задачі: LocalExecutor — у тому ж процесі/машині; Celery/Kubernetes — у віддалених воркерах або под-ах.

**7. Що таке XComs в Airflow? Обмеження і чому не передавати великі датасети?**

XCom (cross-communication) — механізм передачі невеликих даних між задачами (наприклад, словник метрик). Дані зберігаються в metadata DB (або backend). Обмеження: розмір і тип даних (не призначено для великих об’єктів). Великі датасети не варто передавати через XCom через навантаження на БД, обмеження розміру та повільну серіалізацію; краще обмін через зовнішні сховища (файли, S3, таблиці) і передавати лише шляхи або ідентифікатори.

**8. Різниця між Sensor та звичайним оператором (Task). Приклад сенсора в MLOps.**

Звичайний оператор виконує дію один раз і завершується. Sensor періодично перевіряє умову (наприклад, появу файлу) і завершується лише коли умова виконана (або по timeout). У MLOps: FileSensor чекає появи `data/raw/dataset.csv` перед запуском пайплайну (наприклад, після вивантаження даних з джерела).

**9. Що таке ідемпотентність (idempotency) стосовно завдань у DAG? Чому це критично?**

Ідемпотентність — повторне виконання задачі дає той самий результат і не має побічних ефектів, що залежать від кількості запусків. Критично для автоматизованих пайплайнів: при retry або backfill задача може виконуватися кілька разів; якщо вона не ідемпотентна, можливі дублікати даних, перезапис артефактів або неконсистентний стан. Приклад: `dvc repro` ідемпотентний за рахунок кешу; тренування з фіксованим seed дає відтворюваний результат.

**10. Як реалізувати версіонування не тільки коду, а й інфраструктури (Infrastructure as Code) у контексті MLOps?**

Описувати інфраструктуру в коді (Dockerfile, docker-compose, Terraform, Helm тощо) і зберігати в Git. Версіонувати разом із кодом: теги/гілки, коміти. У CI/CD збирати образи з тегами за commit hash, розгортати за однаковими конфігами. Таким чином код, модель і інфраструктура мають спільну історію та відтворюваність.

**11. Різниця між Build Artifact та Model Artifact.**

**Build Artifact** — результат збірки коду/системи (наприклад, Docker-образ, пакет, бінарник), створюється на етапі CI/CD. **Model Artifact** — артефакт ML: збережена модель (наприклад, model.pkl), метрики, діаграми; результат тренування. Обидва можуть зберігатися в артефактному сховищі, але Build Artifact належить до «системи», Model Artifact — до життєвого циклу моделі (навчання, реєстрація, розгортання).

**12. Стратегії обробки помилок (Failure Handling) в Airflow.**

- **Retries** — повторні спроби задачі з затримкою (наприклад, exponential backoff) при збої.
- **Alerts** — сповіщення при падінні (email, Slack, PagerDuty) через callbacks або інтеграції.
- **SLA** — дедлайни виконання; порушення SLA можна відстежувати та реагувати.
- **Trigger rules** — зміна поведінки при збої upstream (наприклад, виконати задачу навіть якщо один із батьків failed).
- **Callback-и** (on_failure, on_retry) — виконання власної логіки при збої або retry.

**13. Що таке Backfill в Airflow і коли виникає потреба у його застосуванні?**

Backfill — заповнення «мінулих» запусків DAG: виконання задач за вказаний діапазон дат (historical run), навіть якщо ці дати вже минули. Потреба виникає коли: DAG додано пізніше і потрібно «догнати» історію; після виправлення помилки перезапустити пайплайн за минулі періоди; один раз обробити архівні дані за минулі дати.

**14. Як забезпечити безпеку конфіденційних даних (API keys, passwords) при використанні CI/CD та оркестраторів?**

Не зберігати секрети в коді чи в комітах. Використовувати секрет-менеджери: у GitHub Actions — Secrets (GITHUB_TOKEN, власні secrets); у Airflow — Variables/Connections з шифруванням (Fernet), або інтеграція з зовнішнім vault (HashiCorp Vault, AWS Secrets Manager). Обмежувати доступ до секретів (RBAC), аудит доступу; у контейнерах передавати через змінні середовища або монтовані файли, а не в образі.
